---
layout:     post
title:      "redis 进阶"
subtitle:   " \"进阶介绍和操作\""
date:       2020-03-12 12:00:00
author:     "Zm"
header-img: "img/post-bg-2020.jpg"
tags:
    - redis
---

# 五、持久化

## 1.什么是持久化

利用永久性存储介质将数据进行保存，在特定的时间将保存的数据进行恢复的工作机制称为持久化。

## 2 RDB

RDB持久化方式，是采用系统快照的方式，将系统数据以数据的形式备份

`RDB的启动方式`

```python
#手动执行一次保存操作
#save指令的执行会阻塞当前Redis服务器，直到当前RDB过程完成为止，有可能会造成长时间阻塞，线上环境不建议使用
save

#手动启动后台保存操作，但不是立即执行
# bgsave命令是针对save阻塞问题做的优化。Redis内部所有涉及到RDB操作都采用bgsave的方式，save命令可以放弃使用。
bgsave

#关机时进行保存
shutdown save

#后台存储过程中如果出现错误现象，是否停止保存操作
#通常默认为开启状态
#bgsave额外配置项（save的配置项都是适用于basave）
stop-writes-on-bgsave-error yes
```

`RDB的配置项`

```python
#设置本地数据库文件名，默认值为 dump.rdb
#通常设置为dump-端口号.rdb
dbfilename dump.rdb
#设置存储.rdb文件的路径
#通常设置成存储空间较大的目录中，目录名称data
dir /data
#设置存储至本地数据库时是否压缩数据，默认为 yes，采用 LZF 压缩
#通常默认为开启状态，如果设置为no，可以节省 CPU 运行时间，但会使存储的文件变大（巨大）
rdbcompression yes
#设置是否进行RDB文件格式校验，该校验过程在写文件和读文件过程均进行
#通常默认为开启状态，如果设置为no，可以节约读写性过程约10%时间消耗，但是存储一定的数据损坏风险
rdbchecksum yes

#满足限定时间范围内key的变化数量达到指定数量即进行持久化
#例如 save 10 1 意味着10s内有一次变化即进行持久化
save second changes
```

3.RDB优缺点

- 优点

    RDB是一个紧凑压缩的二进制文件，存储效率较高

    RDB内部存储的是redis在某个时间点的数据快照，非常适合用于数据备份，全量复制等场景

    RDB恢复数据的速度要比AOF快很多

- 缺点
    RDB方式无论是执行指令还是利用配置，无法做到实时持久化，具有较大的可能性丢失数据

    bgsave指令每次运行要执行fork操作创建子进程，要牺牲掉一些性能

    Redis的众多版本中未进行RDB文件格式的版本统一，有可能出现各版本服务之间数据格式无法兼容现象

## 3.AOF

- AOF(append only file)持久化：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中命令 达到恢复数据的目的。与RDB相比可以简单描述为改记录数据为记录数据产生的过程
- AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式

### 1.AOP持久化三种策略

```python
#AOF持久化的三种策略
always：每次写入操作均同步到AOF文件中，数据零误差，性能较低
*everysec：每秒将缓冲区中的指令同步到AOF文件中，数据准确性较高，性能较高，在系统突然宕机的情况下丢失1秒内的数据
no：由操作系统控制每次同步到AOF文件的周期，整体过程不可控
```

### 	2.AOF配置项

```
#配置是否开启AOF持久化
appendonly yes|no
#配置AOF持久化策略
appendfsync always|everysec|no
#配置AOF持久化文件名称
appendfilename filename
#配置AOF持久化文件保存路径
dir /data
```

### **3.AOF重写**

AOF文件重写是将Redis进程内的数据转化为写命令同步到新AOF文件的过程。简单说就是将对同一个数据的若干个条命令执行结 果转化成最终结果数据对应的指令进行记录。

**AOF重写规则**

- 进程内已超时的数据不再写入文件
- 忽略无效指令，重写时使用进程内数据直接生成，这样新的AOF文件只保留最终数据的写入命令
- 对同一数据的多条写命令合并为一条命令

```python
#手动重写
bgrewriteaof
#自动重写（在配置文件中设置）
auto-aof-rewrite-min-size size #超过size开启重写
auto-aof-rewrite-percentage percentage #超过基数百分比开启重写
#百分比计算方法：(aof_current_size-aof_base_size)/aof_base_size

#自动重写触发比对参数（ 运行指令info Persistence获取具体信息 ）
aof_current_size
aof_base_size
```

# 六、事务

## 1.什么是事务

redis事务就是一个命令执行的队列，将一系列预定义命令包装成一个整体（一个队列）。当执行时，一次性按照添加顺序依次执行，中间不会被打断或者干扰。

## 2、事务的基本操作

```
#开启事务
muti
#结束事务
exec
#取消事务
discard
```

## 3、锁

基于特定条件事务执行——锁

```python
#对 key 添加监视锁，在执行exec前如果key发生了变化，终止事务执行
watch key1 [key2...]
#取消对所有key的监视
unwatch
```

基于特定条件的事务执行——分布式锁

```python
#使用 setnx 给key设置一个公共锁
setnx lock-key value (value可以随意设置，其实就是一个key-value的形式)
#去除锁
del lock-key
#使用expire为锁添加有效期
expire lock-key second
pexpire lock-key milliseconds
```

# 七、删除策略

数据并不一定在我们删除它的时候立刻被删除，通常要遵循某项删除策略

删除策略的选择是为了在内存占用与CPU占用之间寻找一种平衡，顾此失彼都会造成整体redis性能的下降，甚至引发服务器宕机或 内存泄露

## 1.定时删除

创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作

优点：节约内存，到时就删除，快速释放掉不必要的内存占用 

缺点：CPU压力很大，无论CPU此时负载量多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量

总结：用时间换空间

## 2.惰性删除

数据到达过期时间，不做处理。等下次访问该数据时，若过期则执行删除，若未过期，则不执行删除

优点：节约CPU性能，发现必须删除的时候才删除 

缺点：内存压力很大，出现长期占用内存的数据

总结：用空间换时间

## 3.定期删除

周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度

特点1：CPU性能占用设置有峰值，检测频度可自定义设置 

特点2：内存压力不是很大，长期占用内存的冷数据会被持续清理

总结：随机抽查，重点抽查

## 	4.逐出算法（不是策略）

Redis使用内存存储数据，在执行每一个命令前，会调用freeMemoryIfNeeded()检测内存是否充足。

如果内存不满足新加入数据的最低存储要求，redis要临时删除一些数据为当前指令清理存储空间。清理数据 的策略称为逐出算法

**相关配置**

```python
#最大可使用内存
maxmemory
#每次选取待删除数据的个数
maxmemory-samples
#删除策略
maxmemory-policy
---|检测易失数据
	---|volatile-lru：挑选最近最少使用的数据淘汰（上次使用时间据现在最远的）
	---|volatile-lfuu：挑选最近使用次数最少的数据淘汰
	---|volatile-ttlu：挑选最近使用次数最少的数据淘汰
	---|volatile-random：任意选择数据淘汰
---|检测全库数据
	---|allkeys-lru：挑选最近最少使用的数据淘汰
	---|allkeys-lfu：挑选最近使用次数最少的数据淘汰
	---|allkeys-random：任意选择数据淘汰
---|放弃数据驱逐
	---|no-enviction
```

**数据逐出策略配置依据**

使用`INFO`命令输出监控信息，查询缓存 `hit` 和 `miss` 的次数，根据业务需求调优Redis配置

# 八、高级数据类型

## 1.bitmaps

```python
#获取指定key对应偏移量上的bit值
getbit key offset
#设置指定key对应偏移量上的bit值，value只能是1或0
setbit key offset value
#对指定key按位进行交、并、非、异或操作，并将结果保存到destKey中
bitop op destKey key1 [key2...]
#统计指定key中1的数量
bitcount key [start end]
```

## 2.HyperLogLog

`基数`是数据集去重后元素个数

`HyperLogLog` 是用来做基数统计的，运用了LogLog的算法

```python
#添加数据
pfadd key element [element ...]
#统计数据
pfcount key [key ...]
#合并数据
pfmerge destkey sourcekey [sourcekey...]
```

**相关说明**

- 用于进行基数统计，不是集合，**不保存数据**，只记录数量而不是具体数据 

- 核心是基数估算算法，最终数值存在一定误差 

- 误差范围：基数估计的结果是一个带有 0.81% 标准错误的近似值 

- **耗空间极小**，每个hyperloglog key占用了12K的内存用于标记基数 

- pfadd命令不是一次性分配12K内存使用，会随着基数的增加内存逐渐增大 

- Pfmerge命令**合并后占用的存储空间为12K**，无论合并之前数据量多少

## **3.GEO**

`GEO`是专门用来计算直线距离的。

```python
#添加坐标点
geoadd key longitude latitude member [longitude latitude member ...]
georadius key longitude latitude radius m|km|ft|mi [withcoord] [withdist] [withhash] [count count]
#获取坐标点
geopos key member [member ...]
georadiusbymember key member radius m|km|ft|mi [withcoord] [withdist] [withhash] [count count]
#计算坐标点
geodist key member1 member2 [unit]
geohash key member [member ...]
```

